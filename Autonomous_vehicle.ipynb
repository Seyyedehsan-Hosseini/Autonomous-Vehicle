{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80327f4f-8e90-4fd3-ab38-ce445be6a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages needed in this notebook.\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from scipy import signal\n",
    "from signal.ndimage import convolve\n",
    "from skimage import restoration\n",
    "import shutil\n",
    "import albumentations as aug\n",
    "from torchvision.models.resnet import resnet152\n",
    "from torchvision.models.vgg import vgg19\n",
    "from torchvision.models import VGG19_Weights, ResNet152_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLOfrom ultralytics import YOLO\n",
    "import wget\n",
    "if not os.path.exists('resources'): raise TypeError(\"Please create the resources folder and include all required stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9abfb-b5aa-4165-aa0a-573ff9c5001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Img(input_img_path):\n",
    "    if type(input_img_path) != str:\n",
    "        raise ValueError(\"input must be string)\")\n",
    "    img_Orig = cv.imread(input_img_path)\n",
    "    if img_Orig.ndim != 3:\n",
    "        raise ValueError(\"input image must have 3 channels)\")\n",
    "    return img_Orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32708c-0527-4a67-9ca7-bdd23c69b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check images of the dataset###############here\n",
    "########################################################################\n",
    "def transform_image(input_image)\n",
    "     input_image_rgb = cv2.cvtColor(input_image,cv2.COLOR_BGR2RGB)\n",
    "     print('the size of image 1 ==>> ',input_image_rgb.shape)\n",
    "     input_image_grayscale= cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)\n",
    "     return input_image_rgb, input_image_grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb95e18-bc4b-42af-9718-6e44061885dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Augmentation-Horizontal flip\n",
    "def create_augmentation(image,i)\n",
    "    transform = aug.HorizontalFlip(p=0.7)\n",
    "    transformed = transform(image=image)\n",
    "    transformed_image = transformed[\"image\"]\n",
    "    cv.imwrite(\"augmented_image_%d.png\"%i, augmented_image) # The augmented images must be save inside the\n",
    "    #training dataset.A directory must be created in the main code script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17674d73-2847-41cd-8cf8-c8db66a8e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low pass filtering of images\n",
    "def low_pass_filtering(image)\n",
    "    kernel = np.array([[1,2,1],[2,4,2],[1,2,1]])/16.0\n",
    "    conv_img1 = convolve(image, kernel, mode='constant')\n",
    "    return conv_img1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ef12a-ccd0-455e-abe2-26c15f7032dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing function of the image. \n",
    "#Add a for loop to the main function of the script code toapply this to all images of the dataset\n",
    "def resize_image(conv_img1, h, w)\n",
    "    #h,w are the size of the image in height and width \n",
    "    inter_polat = cv.INTER_CUBIC\n",
    "    resized_image = cv.resize(conv_img1, (h, w), interpolation = inter_polat)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36c82b-ee9b-4163-ab1d-d793d53a5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data images for training\n",
    "def arrange_dataset_for_training():\n",
    "    imdir_train = \"resources/dataset/images/\" # Should be configured the suitable dataset's path\n",
    "    label_train = \"resources/dataset/labels/\" #Should be configured the suitable dataset's path\n",
    "    images_path = sorted(glob.glob(imdir_train + '*.' + 'jpg'))\n",
    "    label_path = sorted(glob.glob(label_train + '*.' + 'txt'))\n",
    "    X_train, X_second, y_train, y_second = train_test_split( images_path, label_path, test_size=0.20, random_state=123)\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split( X_second, y_second, test_size=0.25, random_state=123)\n",
    "    return X_train, X_second, y_train, y_second, X_valid, X_test, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e78882-b217-4a47-b05e-81a31a239f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_loading(path_Video):\n",
    "    os.mkdir(\"grayscale_images\")\n",
    "    os.mkdir(\"rgb_images\")\n",
    "    \n",
    "    cap = cv.VideoCapture(cv.samples.findFile(path_Video))\n",
    "    no_Frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(cam.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cam.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print( 'Total number of frames is' , no_Frames )\n",
    "    print( 'The size of each frame width X height is %d X %d' , frame_width, frame_height)\n",
    "    i=0\n",
    "    while(1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('No frames grabbed!')\n",
    "            break\n",
    "        image_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)  \n",
    "        cv.imwrite(\"rgb_images/rgb_frame%d.jpg\" %i, image_rgb)\n",
    "        image_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) #Tranform colored image to grayscale\n",
    "        cv.imwrite(\"grayscale_images/grayscale_frame%d.jpg\" %i, image_gray)\n",
    "        i+=1\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7a575-4f46-41ff-8665-c30bc0eeb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_visualization(path_frame): #Visualise the results of tracking model on the video_frames\n",
    "    os.mkdir(\"annotated_images\")\n",
    "  ############################################################################################  \n",
    "    model = YOLO(\"....\") ######################### Declare the model path that was trained\n",
    "#######################################################################################\n",
    "    results = model.track(path_frame, persist=True)\n",
    "    annotated_frame = results[0].plot()\n",
    "    cv.imwrite(\"annotated_images/object-tracked_frame%d.jpg\" %i, annotated_frame)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
