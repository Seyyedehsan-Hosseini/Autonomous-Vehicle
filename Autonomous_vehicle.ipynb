{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80327f4f-8e90-4fd3-ab38-ce445be6a7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\hseyyedehsan\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Please create the resources folder and include all required stuff",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwget\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[33m'\u001b[39m\u001b[33mresources\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPlease create the resources folder and include all required stuff\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Please create the resources folder and include all required stuff"
     ]
    }
   ],
   "source": [
    "# Import all packages needed in this notebook.\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from scipy import signal\n",
    "from scipy.ndimage import convolve\n",
    "from skimage import restoration\n",
    "import shutil\n",
    "import albumentations as aug\n",
    "from torchvision.models.resnet import resnet152\n",
    "from torchvision.models.vgg import vgg19\n",
    "from torchvision.models import VGG19_Weights, ResNet152_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "import wget\n",
    "\n",
    "if not os.path.exists('resources'):\n",
    "    raise TypeError(\"Please create the resources folder and include all required stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9abfb-b5aa-4165-aa0a-573ff9c5001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Img(input_img_path):\n",
    "    if not isinstance(input_img_path, str):\n",
    "        raise ValueError(\"Input must be a string\")\n",
    "    img_Orig = cv.imread(input_img_path)\n",
    "    if img_Orig is None or img_Orig.ndim != 3:\n",
    "        raise ValueError(\"Input image must have 3 channels\")\n",
    "    return img_Orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32708c-0527-4a67-9ca7-bdd23c69b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check images of the dataset###############here\n",
    "########################################################################\n",
    "def transform_image(input_image):\n",
    "    input_image_rgb = cv.cvtColor(input_image, cv.COLOR_BGR2RGB)\n",
    "    print('The size of image 1 ==>> ', input_image_rgb.shape)\n",
    "    input_image_grayscale = cv.cvtColor(input_image_rgb, cv.COLOR_RGB2GRAY)\n",
    "    return input_image_rgb, input_image_grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb95e18-bc4b-42af-9718-6e44061885dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Augmentation-Horizontal flip\n",
    "def create_augmentation(image, i):\n",
    "    transform = aug.HorizontalFlip(p=0.7)\n",
    "    transformed = transform(image=image)  \n",
    "    transformed_image = transformed[\"image\"]  # Accessing correctly\n",
    "    cv.imwrite(f\"augmented_image_{i}.png\", transformed_image)  \n",
    "    #training dataset.A directory must be created in the main code script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17674d73-2847-41cd-8cf8-c8db66a8e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low pass filtering of images\n",
    "def low_pass_filtering(image):\n",
    "    kernel = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16.0\n",
    "    conv_img1 = convolve(image, kernel, mode='constant')\n",
    "    return conv_img1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ef12a-ccd0-455e-abe2-26c15f7032dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing function of the image. \n",
    "#Add a for loop to the main function of the script code toapply this to all images of the dataset\n",
    "def resize_image(image, h, w):\n",
    "    inter_polat = cv.INTER_CUBIC\n",
    "    resized_image = cv.resize(image, (h, w), interpolation=inter_polat)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36c82b-ee9b-4163-ab1d-d793d53a5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data images for training\n",
    "def arrange_dataset_for_training():\n",
    "    imdir_train = \"resources/dataset/images/\"\n",
    "    label_train = \"resources/dataset/labels/\"\n",
    "    images_path = sorted(glob.glob(imdir_train + '*.jpg'))\n",
    "    label_path = sorted(glob.glob(label_train + '*.txt'))\n",
    "    X_train, X_second, y_train, y_second = train_test_split(images_path, label_path, test_size=0.20, random_state=123)\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_second, y_second, test_size=0.25, random_state=123)\n",
    "    return X_train, X_second, y_train, y_second, X_valid, X_test, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e78882-b217-4a47-b05e-81a31a239f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_loading(path_Video):\n",
    "    os.makedirs(\"grayscale_images\", exist_ok=True)\n",
    "    os.makedirs(\"rgb_images\", exist_ok=True)\n",
    "    \n",
    "    cap = cv.VideoCapture(path_Video)\n",
    "    no_Frames = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f'Total number of frames: {no_Frames}')\n",
    "    print(f'The size of each frame: {frame_width} X {frame_height}')\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('No frames grabbed!')\n",
    "            break\n",
    "        image_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        cv.imwrite(f\"rgb_images/rgb_frame{i}.jpg\", image_rgb)\n",
    "        image_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        cv.imwrite(f\"grayscale_images/grayscale_frame{i}.jpg\", image_gray)\n",
    "        i += 1\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d7a575-4f46-41ff-8665-c30bc0eeb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_visualization(path_frame, i): \n",
    "    # Visualize the results of the tracking model on the video frames\n",
    "    os.makedirs(\"annotated_images\", exist_ok=True)\n",
    "    \n",
    "    ############################################################################################  \n",
    "    # Declare the model path that was trained\n",
    "    model = YOLO(\"model_path.pt\")   \n",
    "    ############################################################################################  \n",
    "\n",
    "    results = model.track(path_frame, persist=True)\n",
    "    \n",
    "    if results and len(results) > 0:  # Ensure results contain at least one frame\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv.imwrite(f\"annotated_images/object-tracked_frame{i}.jpg\", annotated_frame)\n",
    "    else:\n",
    "        print(f\"No objects tracked in frame {i}.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
